<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>_index on Hyperparameter Space</title>
    <link>http://hyperparameter.space/</link>
    <description>Recent content in _index on Hyperparameter Space</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 11 Jun 2017 21:51:17 -0700</lastBuildDate>
    
	<atom:link href="http://hyperparameter.space/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sense and sensitivity (and specificty and utility)</title>
      <link>http://hyperparameter.space/blog/sense-and-sensitivity-and-specificty-and-utility/</link>
      <pubDate>Fri, 05 Jul 2019 14:32:16 -0800</pubDate>
      
      <guid>http://hyperparameter.space/blog/sense-and-sensitivity-and-specificty-and-utility/</guid>
      <description>A recent tweet from Ash Jogalekar got me thinking.
List of compounds medicinal chemists wouldn&amp;#39;t have bothered to pursue because they didn&amp;#39;t fit &amp;quot;intuition&amp;quot; about &amp;quot;druglike&amp;quot; rules
Aspirin
Metformin ($400M revenue)
Cyclosporin (&amp;gt;$1B)
Dimethyl fumarate (&amp;gt;$4B)
In drug discovery, there will always be enough exceptions to the rules
&amp;mdash; Ash Jogalekar (@curiouswavefn) June 24, 2019 
Translating it to more &amp;lsquo;machine-learning-ish&amp;rsquo; language this means that the problem of predicting ultimately successful drug candidates is the pathological case where the cost of your predictions is really high and the rewards are higher but concentrated in a space defined by unmeasured covariates (a molecule might be a terrible drug for one indication but a really good drug for another and the space of possible/probable indications is vast and for the most part unknown).</description>
    </item>
    
    <item>
      <title>Causal models make a comeback</title>
      <link>http://hyperparameter.space/blog/causal-models-make-a-comeback/</link>
      <pubDate>Sun, 23 Dec 2018 14:32:16 -0800</pubDate>
      
      <guid>http://hyperparameter.space/blog/causal-models-make-a-comeback/</guid>
      <description>I really can’t help but smile when hearing folks talking about causal models recently. It looks like causal models are making a comeback! This is a pleasant surprise to me, since I’ve always been a fan of causal inference and I wasn’t sure Judea Pearl’s “Book of Why” was going to catch up or not. But now we even have Pearl on Twitter and there’s more light being shed on work that leverages causal models for various problems or that scales them to very high dimensional settings.</description>
    </item>
    
    <item>
      <title>A single-cell journey from mechanistic to descriptive modeling and back again</title>
      <link>http://hyperparameter.space/blog/a-single-cell-journey-from-mechanistic-to-descriptive-modeling-and-back-again/</link>
      <pubDate>Wed, 06 Sep 2017 23:50:07 -0700</pubDate>
      
      <guid>http://hyperparameter.space/blog/a-single-cell-journey-from-mechanistic-to-descriptive-modeling-and-back-again/</guid>
      <description>MathJax.Hub.Config({ tex2jax: { inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]], displayMath: [[&#39;$$&#39;,&#39;$$&#39;]], processEscapes: true, processEnvironments: true, skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;], TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; }, extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] } } }); MathJax.Hub.Queue(function() { // Fix  tags after MathJax finishes running. This is a // hack to overcome a shortcoming of Markdown. Discussion at // https://github.com/mojombo/jekyll/issues/199 var all = MathJax.Hub.getAllJax(), i; for(i = 0; i Whenever I start thinking about a dataset that I need to model or start reading on a new field, one of the first things I try to get a sense of is the level of mechanistic understanding that we currently have on the phenomena that generated the data, and how that mechanism relates (generalizes) to other phenomena.</description>
    </item>
    
    <item>
      <title>Software is eating AI</title>
      <link>http://hyperparameter.space/blog/software-is-eating-ai/</link>
      <pubDate>Wed, 19 Jul 2017 10:03:29 -0700</pubDate>
      
      <guid>http://hyperparameter.space/blog/software-is-eating-ai/</guid>
      <description>There&amp;rsquo;s a famous line written by legend Marc Andreessen that summarizes the vast power of growth and disruption that commoditized computation has come to have: &amp;ldquo;Software is eating the world&amp;rdquo;. Earlier in the year, Jensen Huang from Nvidia ominously turned the phrase on its head: &amp;ldquo;Software is eating the world, but AI is going to eat software&amp;rdquo;. In many ways, I think this prophecy will indeed come to pass. Current software has become so pervasive because we have tools that translate tasks that would seem daunting (configure millions of circuit states to solve millions of repetitive tasks) into programming languages that are easy to write, learn, and teach.</description>
    </item>
    
    <item>
      <title>When not to use deep learning</title>
      <link>http://hyperparameter.space/blog/when-not-to-use-deep-learning/</link>
      <pubDate>Fri, 16 Jun 2017 21:17:31 -0700</pubDate>
      
      <guid>http://hyperparameter.space/blog/when-not-to-use-deep-learning/</guid>
      <description>I know it&amp;rsquo;s a weird way to start a blog with a negative, but there was a wave of discussion in the last few days that I think serves as a good hook for some topics on which I&amp;rsquo;ve been thinking recently. It all started with a post in the Simply Stats blog by Jeff Leek on the caveats of using deep learning in the small sample size regime.</description>
    </item>
    
    <item>
      <title>about</title>
      <link>http://hyperparameter.space/about/</link>
      <pubDate>Tue, 11 Apr 2017 16:23:34 -0700</pubDate>
      
      <guid>http://hyperparameter.space/about/</guid>
      <description>My full name is Sergio Pablo Sanchez Cordero Gonzalez but I usually go (and publish) by Pablo Cordero. I&amp;rsquo;m currently a computational biologist at Hexagon Bio, mining the world&amp;rsquo;s fungalome for drugs. Previously, I&amp;rsquo;ve been a postdoc at UCSC&amp;rsquo;s systems biology group doing applied machine learning research on single-cell measurements and I did my doctoral work in RNA structure, the genomics of cardiovascular disease, and other things with Rhiju Das and Euan Ashley at Stanford University.</description>
    </item>
    
  </channel>
</rss>