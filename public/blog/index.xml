<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on Hyperparameter Space</title>
    <link>http://hyperparameter.space/blog/</link>
    <description>Recent content in Blog on Hyperparameter Space</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 23 Dec 2018 14:32:16 -0800</lastBuildDate>
    
	<atom:link href="http://hyperparameter.space/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Causal models make a comeback</title>
      <link>http://hyperparameter.space/blog/causal-models-make-a-comeback/</link>
      <pubDate>Sun, 23 Dec 2018 14:32:16 -0800</pubDate>
      
      <guid>http://hyperparameter.space/blog/causal-models-make-a-comeback/</guid>
      <description>I really can’t help but smile when hearing folks talking about causal models recently. It looks like causal models are making a comeback! This is a pleasant surprise to me, since I’ve always been a fan of causal inference and I wasn’t sure Judea Pearl’s “Book of Why” was going to catch up or not. But now we even have Pearl on Twitter and there’s more light being shed on work that leverages causal models for various problems or that scales them to very high dimensional settings.</description>
    </item>
    
    <item>
      <title>A single-cell journey from mechanistic to descriptive modeling and back again</title>
      <link>http://hyperparameter.space/blog/a-single-cell-journey-from-mechanistic-to-descriptive-modeling-and-back-again/</link>
      <pubDate>Wed, 06 Sep 2017 23:50:07 -0700</pubDate>
      
      <guid>http://hyperparameter.space/blog/a-single-cell-journey-from-mechanistic-to-descriptive-modeling-and-back-again/</guid>
      <description>MathJax.Hub.Config({ tex2jax: { inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]], displayMath: [[&#39;$$&#39;,&#39;$$&#39;]], processEscapes: true, processEnvironments: true, skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;], TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; }, extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] } } }); MathJax.Hub.Queue(function() { // Fix  tags after MathJax finishes running. This is a // hack to overcome a shortcoming of Markdown. Discussion at // https://github.com/mojombo/jekyll/issues/199 var all = MathJax.Hub.getAllJax(), i; for(i = 0; i Whenever I start thinking about a dataset that I need to model or start reading on a new field, one of the first things I try to get a sense of is the level of mechanistic understanding that we currently have on the phenomena that generated the data, and how that mechanism relates (generalizes) to other phenomena.</description>
    </item>
    
    <item>
      <title>Software is eating AI</title>
      <link>http://hyperparameter.space/blog/software-is-eating-ai/</link>
      <pubDate>Wed, 19 Jul 2017 10:03:29 -0700</pubDate>
      
      <guid>http://hyperparameter.space/blog/software-is-eating-ai/</guid>
      <description>There&amp;rsquo;s a famous line written by legend Marc Andreessen that summarizes the vast power of growth and disruption that commoditized computation has come to have: &amp;ldquo;Software is eating the world&amp;rdquo;. Earlier in the year, Jensen Huang from Nvidia ominously turned the phrase on its head: &amp;ldquo;Software is eating the world, but AI is going to eat software&amp;rdquo;. In many ways, I think this prophecy will indeed come to pass. Current software has become so pervasive because we have tools that translate tasks that would seem daunting (configure millions of circuit states to solve millions of repetitive tasks) into programming languages that are easy to write, learn, and teach.</description>
    </item>
    
    <item>
      <title>When not to use deep learning</title>
      <link>http://hyperparameter.space/blog/when-not-to-use-deep-learning/</link>
      <pubDate>Fri, 16 Jun 2017 21:17:31 -0700</pubDate>
      
      <guid>http://hyperparameter.space/blog/when-not-to-use-deep-learning/</guid>
      <description>I know it&amp;rsquo;s a weird way to start a blog with a negative, but there was a wave of discussion in the last few days that I think serves as a good hook for some topics on which I&amp;rsquo;ve been thinking recently. It all started with a post in the Simply Stats blog by Jeff Leek on the caveats of using deep learning in the small sample size regime.</description>
    </item>
    
  </channel>
</rss>